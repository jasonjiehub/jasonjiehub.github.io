<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="我按照慕课网上的教程来学习搭建hadoop-1.2.1环境，可是在start-all.sh这步的时候一直通不过，命令行报如下错误12345678[@soguo /home/denglinjie/hadoop]# start-all.sh   Warning: $HADOOP_HOME is deprecated.    starting namenode, logging to /home/den">
<meta name="keywords" content="hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的">
<meta property="og:url" content="http://yoursite.com/2017/09/08/2017-09-12-我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="我按照慕课网上的教程来学习搭建hadoop-1.2.1环境，可是在start-all.sh这步的时候一直通不过，命令行报如下错误12345678[@soguo /home/denglinjie/hadoop]# start-all.sh   Warning: $HADOOP_HOME is deprecated.    starting namenode, logging to /home/den">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-12-18T02:52:45.199Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的">
<meta name="twitter:description" content="我按照慕课网上的教程来学习搭建hadoop-1.2.1环境，可是在start-all.sh这步的时候一直通不过，命令行报如下错误12345678[@soguo /home/denglinjie/hadoop]# start-all.sh   Warning: $HADOOP_HOME is deprecated.    starting namenode, logging to /home/den">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">about</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-2017-09-12-我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/09/08/2017-09-12-我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的/" class="article-date">
  <time datetime="2017-09-07T16:00:00.000Z" itemprop="datePublished">2017-09-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>我按照慕课网上的教程来学习搭建hadoop-1.2.1环境，可是在start-all.sh这步的时候一直通不过，命令行报如下错误<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[@soguo /home/denglinjie/hadoop]# start-all.sh   </span><br><span class="line">Warning: $HADOOP_HOME is deprecated.  </span><br><span class="line">  </span><br><span class="line">starting namenode, logging to /home/denglinjie/hadoop-1.2.1/logs/hadoop-denglinjie-namenode-bjzw_30_4.out  </span><br><span class="line">localhost: ssh_exchange_identification: Connection closed by remote host  </span><br><span class="line">localhost: ssh_exchange_identification: Connection closed by remote host  </span><br><span class="line">starting jobtracker, logging to /home/denglinjie/hadoop-1.2.1/logs/hadoop-denglinjie-jobtracker-bjzw_30_4.out  </span><br><span class="line">localhost: ssh_exchange_identification: Connection closed by remote host</span><br></pre></td></tr></table></figure></p>
<p>日志文件报如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">2017-03-02 19:28:00,951 WARN org.apache.hadoop.hdfs.DFSClient: Error Recovery for null bad datanode[0] nodes == null  </span><br><span class="line">2017-03-02 19:28:00,952 WARN org.apache.hadoop.hdfs.DFSClient: Could not get block locations. Source file &quot;/home/denglinjie/hadoop/tmp/mapred/system/jobtracker.info&quot; - Aborting  </span><br><span class="line">...  </span><br><span class="line">2017-03-02 19:28:00,952 WARN org.apache.hadoop.mapred.JobTracker: Writing to file hdfs://localhost:9063/home/denglinjie/hadoop/tmp/mapred/system/jobtracker.info failed!  </span><br><span class="line">2017-03-02 19:28:00,952 WARN org.apache.hadoop.mapred.JobTracker: FileSystem is not ready yet!  </span><br><span class="line">2017-03-02 19:28:00,954 WARN org.apache.hadoop.mapred.JobTracker: Failed to initialize recovery manager.   </span><br><span class="line">org.apache.hadoop.ipc.RemoteException: java.io.IOException: File /home/denglinjie/hadoop/tmp/mapred/system/jobtracker.info could only be replicated to 0 nodes, instead of 1  </span><br><span class="line">    at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:1920)  </span><br><span class="line">    at org.apache.hadoop.hdfs.server.namenode.NameNode.addBlock(NameNode.java:783)  </span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  </span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)  </span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)  </span><br><span class="line">    at java.lang.reflect.Method.invoke(Method.java:597)  </span><br><span class="line">    at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:587)  </span><br><span class="line">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1432)  </span><br><span class="line">    at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1428)  </span><br><span class="line">    at java.security.AccessController.doPrivileged(Native Method)  </span><br><span class="line">    at javax.security.auth.Subject.doAs(Subject.java:396)  </span><br><span class="line">    at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1190)  </span><br><span class="line">    at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1426)  </span><br><span class="line">  </span><br><span class="line">    at org.apache.hadoop.ipc.Client.call(Client.java:1113)  </span><br><span class="line">    at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)  </span><br><span class="line">    at com.sun.proxy.$Proxy7.addBlock(Unknown Source)  </span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  </span><br><span class="line">    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)  </span><br><span class="line">    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)  </span><br><span class="line">    at java.lang.reflect.Method.invoke(Method.java:597)  </span><br><span class="line">    at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)  </span><br><span class="line">    at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)  </span><br><span class="line">    at com.sun.proxy.$Proxy7.addBlock(Unknown Source)  </span><br><span class="line">    at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.locateFollowingBlock(DFSClient.java:3720)  </span><br><span class="line">    at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.nextBlockOutputStream(DFSClient.java:3580)  </span><br><span class="line">    at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream.access$2600(DFSClient.java:2783)  </span><br><span class="line">    at org.apache.hadoop.hdfs.DFSClient$DFSOutputStream$DataStreamer.run(DFSClient.java:3023)</span><br></pre></td></tr></table></figure></p>
<p>首先解决命令行报的错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost: ssh_exchange_identification: Connection closed by remote host</span><br></pre></td></tr></table></figure></p>
<p>从google中找问题，发现网上的解决办法千奇百怪，有的说要修改slaves和masters文件中的主机名为ip地址，有的说是因为主机名不能有下划线，但是其实我的主机名用的默认的localhost，总之尝试了网上的各种解决办法，都失败，网上大多数办法都是集中在如下几个配置文件配置的问题上：<br>core-site.xml,  mapred-site.xml,  hdfs-site.xml<br>不过无论我怎么配置都不行，于是一下午都没有找到原因<br>第二天来之后，我想了下也许慕课网那个视频教程是精简版的呢，于是我索性自己从google上搜索了一篇hadoop-1.2.1搭建本地伪分布式安装的教程，按照别人的教程来，文章地址如下：<br><a href="https://hexo2hexo.github.io/hadoop1.2.1%E5%AE%89%E8%A3%85/" target="_blank" rel="noopener">https://hexo2hexo.github.io/hadoop1.2.1%E5%AE%89%E8%A3%85/</a><br>这篇文章中的步骤其实和慕课网的视频教程步骤基本雷同，但是多了如下步骤：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1.生成秘钥  </span><br><span class="line">ssh-keygen -t rsa  </span><br><span class="line">2.一直回车即可,然后进入.ssh目录,执行命令  </span><br><span class="line">cd ~/.ssh  </span><br><span class="line">cp id_rsa.pub authorized_keys  </span><br><span class="line">3.检查是否需要密码  </span><br><span class="line">ssh localhost</span><br></pre></td></tr></table></figure></p>
<p>这很显然是设置免密码登陆啊，于是我按照它的步骤操作了一遍，发现执行到ssh localhost这步的时候，报了如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh_exchange_identification: Connection closed by remote host</span><br></pre></td></tr></table></figure></p>
<p>我一看，这步跟我启动hadoop的时候报的错误是一样的吗？感情启动hadoop的时候就是在执行ssh  localhost这步呢，于是原因也找到了，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jobtracker.info could only be replicated to 0 nodes, instead of 1</span><br></pre></td></tr></table></figure></p>
<p>上面这个应该只是ssh执行失败的结果，而不是造成问题的主要原因，既然这样那只要保证ssh  localhost成功登陆本地主机不就OK了吗<br>于是又在网上一通找，</p>
<p>首先开启了/etc/ssh/sshd_config配置文件中的如下几个选项<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RSAAuthentication yes  </span><br><span class="line">PubkeyAuthentication yes  </span><br><span class="line">AuthorizedKeysFile  .ssh/authorized_key</span><br></pre></td></tr></table></figure></p>
<p>然后重启ssh服务</p>
<h1 id="service-sshd-restart"><a href="#service-sshd-restart" class="headerlink" title="service  sshd   restart"></a>service  sshd   restart</h1><p>发现不好使，还是登陆不上，然后又把/etc/hosts.deny文件中的</p>
<h1 id="sshd-ALL"><a href="#sshd-ALL" class="headerlink" title="sshd  ALL"></a>sshd  ALL</h1><p>这行注释打开，重启sshd服务，再次登陆成功了！<br>于是迫不及待的重新执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># stop-all.sh  </span><br><span class="line"># hadoop namenode -format  </span><br><span class="line"># start-all.sh</span><br></pre></td></tr></table></figure></p>
<p>成功了！！！<br>执行jps命令，成功看到了如下输出：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[@sohuo ~/hadoop-1.2.1]$ jps  </span><br><span class="line">30999 Jps  </span><br><span class="line">30510 DataNode  </span><br><span class="line">30651 SecondaryNameNode  </span><br><span class="line">30885 TaskTracker  </span><br><span class="line">30395 NameNode  </span><br><span class="line">30760 JobTracker</span><br></pre></td></tr></table></figure></p>
<p>然后说下日志文件报的错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jobtracker.info could only be replicated to 0 nodes, instead of 1</span><br></pre></td></tr></table></figure></p>
<p>这个问题，网上的解决办法也是多种多样，有的说是防火墙没关闭，但是其实我的机器根本没有防火墙。有的说是目录没有删除干净等等。<br>当然最后解决我问题的还是磁盘空间不足的问题。<br>在core-site.xml文件和hdfs-site.xml文件中配置的有namenode和datanode放置的目录，我的机器上，这个目录所在盘已经满了，于是我修改这两个文件配置到了另外一个盘上，问题就解决了。<br>其实一开始，我把hadoop-1.2.1.tar.gz文件解压到我自己的用户家目录下的时候就发现莫名其妙的异常，就是加压后的一些脚本文件内容都是空的，我以为是解压的过程中丢失了，于是我重新解压，才发现日志中说磁盘空间不足。<br>但是我又想在自己用户下工作，怎么办呢？于是我将hadoop-1.2.1.tar.gz文件移动到了一个剩余空间充裕的磁盘目录下，并解压，然后在我自己的家目录下为解压后的hadoop目录创建了软的符号链接，这样就可以了。<br>但是我没有意识到，我在core-site.xml文件和hdfs-site.xml文件中为hadoop指定的namenode和datanode存放的目录还是在我自己的家目录下，而这些目录就不是符号链接了，导致空间不足，所以报了上述错误，终于圆满解决。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/09/08/2017-09-12-我是如何解决jobtracker.info could only be replicated to 0 nodes, instead of 1这个问题的/" data-id="cjpt6aanw000abqmzxk0cof3b" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hadoop/">hadoop</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/09/08/2017-09-08-Spring源码分析之lazy-init属性的配置/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Spring源码分析之lazy-init属性的配置
        
      </div>
    </a>
  
  
    <a href="/2017/09/08/2017-09-08-Spring IOC学习心得之Bean对IOC容器的感知/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Spring IOC学习心得之Bean对IOC容器的感知</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/">Java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linux/">Linux</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Spring/">Spring</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hadoop/">hadoop</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Java/" style="font-size: 20px;">Java</a> <a href="/tags/Linux/" style="font-size: 20px;">Linux</a> <a href="/tags/Spring/" style="font-size: 20px;">Spring</a> <a href="/tags/hadoop/" style="font-size: 10px;">hadoop</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/18/��һƪ���/">��һƪ���</a>
          </li>
        
          <li>
            <a href="/2018/12/18/my-site/">my_site</a>
          </li>
        
          <li>
            <a href="/2018/12/18/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2017/09/08/2017-09-08-Spring IOC学习心得之注册bean的依赖关系/">Spring IOC学习心得之注册bean的依赖关系</a>
          </li>
        
          <li>
            <a href="/2017/09/08/2017-09-08-Spring IOC学习心得之源码级分析ContextLoaderListener的作用(IOC容器初始化入口)/">Spring IOC学习心得之源码级分析ContextLoaderListener的作用(IOC容器初始化入口)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">about</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>